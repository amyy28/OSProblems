Following Udemy OS course by Vignesh Sekar.
Adding Notes here + some of my own thoughts.

=Overview=

Operating Systems act as resource managers, where resources can be anything like CPU time, memory,
etc. They contain various algorithms for resource management like scheduling of processes, etc.

OS gets loaded into RAM at boot time, and remains active till the system is active. OS space or
kernel space is the term used for the region in memory occupied by the OS. The remaining part is
called user space.

Program is the term used for the executables present on the hard disk. When launching the program,
a process is created like a copy in the hard disk; there could be multiple instances of the program
launched as separate processes. This could be loaded later into RAM for execution.
A process can be various states like new, ready, running, I/O, etc.

Every process has a PCB and some attributes associated with it. This is collectively also called as
context of the process.

Process Control Block or PCB is some memory space created for a process. It consists of Function
Call Stack (including stack variables), a heap for dynamic allocations, space for static and global
variables, and the actual program code. The Program Code is called Code Segment and rest is Data
segment.

Process Attributes like Process ID, Program Counter value, various register values, etc., help in
process save-restore.

=Scheduling Algorithms=

Can be pre-emptive (utilizing save restore) or non pre-emptive (letting processes run to complete).
Scheduling Algorithms are only applied for processes in ready state.

If the expected time taken, arrival time info. is available then we can design some algorithm that
could minimize average waiting time, turnaround time, total schedule length, etc.
Gantt charts can be used to find these times above.
SJF (shortest job first) relies on expected time taken for a process to schedule.
SRTF (shortest remaining time first) also relies on the same, a bit like modification of SJF.
SRTF is premptive algorithm but SJF is non-premptive.
HRRN (Highest Response Ratio Next) is a non-premptive algorithm, which is a modification of SJF.
The response ratio is (Waiting Time + Running Time) / (Running Time). As a process waits for
longer durations, its response ratio will rise and could become higher than others with lower
running time. This can avoid the starvation problem where long running time processes can possibly
wait indefinitely for being scheduled.

Thought: In many real use cases the expected time taken information might not be available.

FCFS doesn't suffer from starvation (where there is a chance of a process waiting indefinitely).

Round Robin algorithm adds the concept of a "Time Quantum". Whenever a process takes the CPU for
time units equal to "Time Quantum", and there is some other ready process; preemption occurs.
All ready processes are kept in a FIFO queue, preempted process is added at the end of the queue.
The first ready process at the head of the queue is picked next for scheduling.

Higher time quantum can reduce context switches, but can cause larger waits for waiting processes.

FCFS and RR don't need the expected time taken information. RR avoids the "convoy effect" problem
present in FCFS where large time consuming process can block short time consuming process for a
long time.

Priority scheduling adds an additional priority to process attributes. These can be preemptive as
well.

A process state diagram can be created to see the state transition of a process, at various events.
Process can be sent to suspend state from ready state, when it is moved from RAM to hard disk; if
there is no more room in RAM for a new process but a high priority process comes in. Later it can
come back to ready space when RAM is available.

After scheduler decides what process to schedule next, it calls the dispatcher which loads the
various registers with process attributes to execute further.

=Memory Allocation Techniques=

Actual RAM addresses are physical address, these addresses lie in what we call as physical address
space.
A process also has addresses for various things like functions, etc., these are in a logical
(or virtual) address space.

Contiguous allocation is if the addresses of the process is placed in a contiguous region of RAM
physical addresses. The RAM can be made to use fixed/variable partitioning. In fixed partitioning,
before a process is loaded, the RAM is split into some paritions. Processes are placed into one
suitable partition when being loaded to RAM. A parition can't hold more than 1 process. In variable
paritioning, the RAM is not split into any partitions beforehand. When process is loaded, it gets
a new parition which has the required amount of memory that it needs.
There is an internal fragmentation problem in fixed partitioning, where there could be extra size
in the partition for a process that it doesn't need, but it got because the partition was created
beforehand. There is an external fragmentation problem in variable partitioning, where based on
how processes came and went earlier, there might be enough space available to accomodate a new
process but it is not contiguous and thus the new process can't be allocated in RAM.

Compaction and Paging are used to avoid fragmentation problems. Compaction causes the allocated
regions to be made contiguous, at regular intervals; so that the free space also becomes
contiguous. But compaction is a time consuming operation, and the CPU is running compaction code
instead of running actual user processes.

Paging is used for non-contiguous allocations and can solve the problems observed with earlier
methods described above.
